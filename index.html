<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <script src="https://telegram.org/js/telegram-web-app.js"></script>
    <script async src="https://docs.opencv.org/4.x/opencv.js" type="text/javascript"></script>
    <script type="module" src="https://cdn.jsdelivr.net/npm/three@0.168.0/build/three.module.js"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        body {
            background: #000;
            color: #000;
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', system-ui, sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            min-height: 100vh;
            overflow: hidden;
            position: relative;
        }
        #webgl-canvas {
            position: absolute;
            top: 0; left: 0;
            width: 100%; height: 100%;
            z-index: 0;
        }
        .content {
            position: relative;
            z-index: 1;
            display: flex;
            flex-direction: column;
            align-items: center;
            width: 100%;
            padding: 20px;
        }
        .soul-container {
            position: relative;
            margin-bottom: 30px;
        }
        .soul-orb {
            position: relative;
            width: 200px;
            height: 200px;
            border-radius: 50%;
            background: radial-gradient(circle at 35% 35%,
                rgba(255, 255, 255, 0.9) 0%,
                rgba(200, 200, 200, 0.6) 20%,
                rgba(100, 100, 100, 0.4) 40%,
                rgba(40, 40, 40, 0.8) 70%,
                rgba(0, 0, 0, 1) 100%
            );
            box-shadow:
                0 0 60px rgba(255, 255, 255, 0.3),
                0 0 100px rgba(255, 255, 255, 0.1),
                inset -30px -30px 80px rgba(0, 0, 0, 0.9),
                inset 30px 30px 60px rgba(255, 255, 255, 0.05);
            animation: breathe 4s infinite ease-in-out;
            cursor: pointer;
            transition: all 0.3s ease;
        }
        .soul-orb::before {
            content: '';
            position: absolute;
            top: 18%;
            left: 25%;
            width: 35%;
            height: 35%;
            border-radius: 50%;
            background: radial-gradient(circle,
                rgba(255, 255, 255, 0.9) 0%,
                rgba(255, 255, 255, 0.4) 40%,
                transparent 70%
            );
            filter: blur(8px);
        }
        .soul-orb::after {
            content: '';
            position: absolute;
            inset: 0;
            border-radius: 50%;
            background: radial-gradient(circle at 70% 70%,
                transparent 40%,
                rgba(0, 0, 0, 0.6) 80%
            );
        }
        .aura {
            position: absolute;
            inset: -20px;
            border-radius: 50%;
            background: radial-gradient(circle,
                transparent 60%,
                rgba(255, 255, 255, 0.1) 70%,
                transparent 100%
            );
            animation: auraGlow 3s infinite ease-in-out;
            opacity: 0.5;
        }
        .soul-orb.listening { animation: pulse 1.2s infinite ease-in-out; box-shadow: 0 0 80px rgba(255,255,255,0.5), 0 0 120px rgba(255,255,255,0.3), inset -30px -30px 80px rgba(0,0,0,0.9), inset 30px 30px 60px rgba(255,255,255,0.05); }
        .soul-orb.listening .aura { animation: auraExpand 1.2s infinite ease-in-out; }
        .soul-orb.speaking { animation: vibrate 0.15s infinite linear; box-shadow: 0 0 100px rgba(255,255,255,0.7), 0 0 150px rgba(255,255,255,0.4), inset -30px -30px 80px rgba(0,0,0,0.9), inset 30px 30px 60px rgba(255,255,255,0.05); }
        .soul-orb.thinking { animation: rotate 2s infinite linear; }
        /* === Self-Awareness: –æ—Ç—Ä–∞–∂–µ–Ω–∏–µ === */
        .soul-orb.reflecting {
            animation: breathe 5s infinite ease-in-out;
            box-shadow: 0 0 60px rgba(255,255,255,0.3),
                        0 0 100px rgba(0,0,255,0.2);
        }
        @keyframes breathe { 0%,100%{transform:scale(1)} 50%{transform:scale(1.05)} }
        @keyframes pulse { 0%,100%{transform:scale(1)} 50%{transform:scale(1.12)} }
        @keyframes vibrate { 0%{transform:translate(0,0) rotate(0)} 25%{transform:translate(-3px,3px) rotate(-1deg)} 50%{transform:translate(3px,-3px) rotate(1deg)} 75%{transform:translate(-3px,-3px) rotate(-0.5deg)} 100%{transform:translate(0,0) rotate(0)} }
        @keyframes rotate { from{transform:rotate(0)} to{transform:rotate(360deg)} }
        @keyframes auraGlow { 0%,100%{opacity:0.3} 50%{opacity:0.6} }
        @keyframes auraExpand { 0%,100%{transform:scale(1);opacity:0.5} 50%{transform:scale(1.3);opacity:0.8} }
        
        #status {
            font-size: 19px;
            font-weight: 300;
            letter-spacing: 3px;
            text-transform: uppercase;
            opacity: 0.9;
            margin-bottom: 15px;
            text-shadow: 0 0 15px rgba(255,255,255,0.5);
            animation: statusFade 2s infinite ease-in-out;
            color: rgba(255, 255, 255, 0.8);
        }
        
        @keyframes statusFade { 0%,100%{opacity:0.7} 50%{opacity:1} }
        
        #transcript {
            font-size: 15px;
            max-width: 90%;
            text-align: center;
            opacity: 0.9;
            line-height: 1.6;
            padding: 15px;
            max-height: 180px;
            overflow-y: auto;
            color: rgba(255, 255, 255, 0.9);
            background: transparent;
            backdrop-filter: none;
            box-shadow: none;
            border: none;
        }
        
        #transcript::-webkit-scrollbar { width: 3px; }
        #transcript::-webkit-scrollbar-track { background: transparent; }
        #transcript::-webkit-scrollbar-thumb { background: rgba(255,255,255,0.2); border-radius: 2px; }
        
        .tap-hint {
            position: absolute;
            bottom: 20px;
            font-size: 12px;
            opacity: 0.4;
            letter-spacing: 1px;
            color: rgba(255, 255, 255, 0.6);
        }
        /* –≠—Ñ—Ñ–µ–∫—Ç –∫—É—Ä—Å–æ—Ä–∞ –¥–ª—è –ø–µ—á–∞—Ç–∏ */
        .typing-cursor::after {
            content: '‚ñã';
            display: inline-block;
            vertical-align: bottom;
            animation: blink 1s step-end infinite;
            color: rgba(255, 255, 255, 0.8);
            margin-left: 2px;
        }

        @keyframes blink {
            0%, 100% { opacity: 1; }
            50% { opacity: 0; }
        }
    </style>
</head>
<body>
    <canvas id="webgl-canvas"></canvas>

    <!-- Only video element for camera -->
    <video id="camera-video" autoplay playsinline style="display:none; position:absolute; left:0; top:0; width:100vw; height:100vh; object-fit:cover; z-index:5; pointer-events:none;"></video>

    <div class="content">
        <div class="soul-container">
            <div class="aura"></div>
            <div id="orb" class="soul-orb"></div>
        </div>
       
        <div id="status">resonating</div>
        <div id="transcript"></div>
    </div>

    <script type="module">
        import * as THREE from 'https://cdn.jsdelivr.net/npm/three@0.168.0/build/three.module.js';

        const canvas = document.getElementById('webgl-canvas');
        const renderer = new THREE.WebGLRenderer({ canvas, alpha: true, antialias: true });
        renderer.setPixelRatio(window.devicePixelRatio);
        renderer.setSize(window.innerWidth, window.innerHeight);
        renderer.outputColorSpace = THREE.SRGBColorSpace;
        renderer.toneMapping = THREE.ACESFilmicToneMapping;
        renderer.toneMappingExposure = 1.1;

        const scene = new THREE.Scene();

        // === Feedback RenderTarget initialization ===
        const rtParams = {
            minFilter: THREE.LinearFilter,
            magFilter: THREE.LinearFilter,
            format: THREE.RGBAFormat
        };

        let feedbackRT1 = new THREE.WebGLRenderTarget(window.innerWidth, window.innerHeight, rtParams);
        let feedbackRT2 = new THREE.WebGLRenderTarget(window.innerWidth, window.innerHeight, rtParams);

        const camera = new THREE.PerspectiveCamera(60, window.innerWidth / window.innerHeight, 0.1, 100);
        camera.position.z = 5;

        // XDust —à–µ–π–¥–µ—Ä –¥–ª—è —á–∞—Å—Ç–∏—Ü
        const vertexShader = `
            attribute float size;
            attribute vec3 customColor;
            varying vec3 vColor;
            void main() {
                vColor = customColor;
                vec4 mvPosition = modelViewMatrix * vec4(position, 1.0);
                gl_PointSize = size * (300.0 / -mvPosition.z);
                gl_Position = projectionMatrix * mvPosition;
            }
        `;

        const fragmentShader = `
            uniform float time;
            const float PI = 3.141592653589793;
            varying vec3 vColor;

            vec3 XDust(vec3 p, vec3 c1, vec3 c2, vec3 c3) {
                vec3 dir = normalize(p - vec3(0.5, 0.5, 0.0));
                float d = length(dir);
                float anim = time * 0.5;
                if (d > 0.98 && d < 1.02) {
                    float t = fract(sin(d * PI) * anim + c1.x);
                    return mix(c1, c2, t);
                } else {
                    float t = fract(cos(d * PI) * anim + c2.y);
                    return mix(c2, c3, t);
                }
            }

            void main() {
                vec3 p = gl_PointCoord.xyx / vec3(2.0);
                vec3 color = XDust(p, vec3(1.0, 0.0, 0.7), vec3(0.2, 0.8, 1.0), vec3(0.6, 0.5, 1.0));
                float dist = length(gl_PointCoord - vec2(0.5));
                float alpha = 1.0 - smoothstep(0.0, 0.5, dist);
                gl_FragColor = vec4(color * vColor, alpha * 0.8);
            }
        `;

        // === Fullscreen quad for feedback and blur ===
        const feedbackScene = new THREE.Scene();
        const feedbackCamera = new THREE.OrthographicCamera(-1, 1, 1, -1, 0, 1);

        const feedbackMaterial = new THREE.ShaderMaterial({
            uniforms: {
                tOld: { value: null },
                tNew: { value: null },
                decay: { value: 0.96 },
                resolution: { value: new THREE.Vector2(window.innerWidth, window.innerHeight) }
            },
            vertexShader: `
                varying vec2 vUv;
                void main() {
                    vUv = uv;
                    gl_Position = vec4(position, 1.0);
                }
            `,
            fragmentShader: `
    varying vec2 vUv;
    uniform sampler2D tOld;
    uniform sampler2D tNew;
    uniform float decay;
    uniform vec2 resolution;

    // hash noise
    float hash(vec2 p) {
        return fract(sin(dot(p, vec2(127.1, 311.7))) * 43176.5453123);
    }

    vec2 noiseDir(vec2 uv) {
        float n = hash(uv * resolution);
        float a = n * 6.28318530718;
        return vec2(cos(a), sin(a));
    }

    vec4 noiseBlur(sampler2D tex, vec2 uv) {
        vec2 px = 1.0 / resolution;
        vec2 dir = noiseDir(uv);

        vec4 col = vec4(0.0);
        col += texture2D(tex, uv) * 0.314;
        col += texture2D(tex, uv + dir * px * 1.0) * 0.22;
        col += texture2D(tex, uv - dir * px * 1.0) * 0.22;
        col += texture2D(tex, uv + dir * px * 2.5) * 0.11;
        col += texture2D(tex, uv - dir * px * 2.5) * 0.11;

        return col;
    }

    void main() {
        vec4 oldCol = noiseBlur(tOld, vUv) * decay;
        vec4 newCol = texture2D(tNew, vUv);
        gl_FragColor = max(oldCol * 0.96, newCol);
    }
`,
            transparent: true
        });

        const quad = new THREE.Mesh(new THREE.PlaneGeometry(2, 2), feedbackMaterial);
        feedbackScene.add(quad);

        const particleCount = 15000;
        const positions = new Float32Array(particleCount * 3);
        const sizes = new Float32Array(particleCount);
        const colors = new Float32Array(particleCount * 3);

        for (let i = 0; i < particleCount; i++) {
            positions[i * 3] = (Math.random() - 0.5) * 10;
            positions[i * 3 + 1] = (Math.random() - 0.5) * 10;
            positions[i * 3 + 2] = (Math.random() - 0.5) * 10;

            sizes[i] = Math.random() * 3 + 1;

            colors[i * 3] = 1;
            colors[i * 3 + 1] = 1;
            colors[i * 3 + 2] = 1;
        }

        const geometry = new THREE.BufferGeometry();
        geometry.setAttribute('position', new THREE.BufferAttribute(positions, 3));
        geometry.setAttribute('size', new THREE.BufferAttribute(sizes, 1));
        geometry.setAttribute('customColor', new THREE.BufferAttribute(colors, 3));

        const material = new THREE.ShaderMaterial({
            uniforms: { time: { value: 0 } },
            vertexShader,
            fragmentShader,
            transparent: true,
            depthWrite: false,
            blending: THREE.AdditiveBlending
        });

        const particles = new THREE.Points(geometry, material);
        scene.add(particles);

        function animate() {
            requestAnimationFrame(animate);

            material.uniforms.time.value += 0.01;
            particles.rotation.y += 0.0002;

            // —Ä–µ–Ω–¥–µ—Ä —á–∞—Å—Ç–∏—Ü –≤ –Ω–æ–≤—ã–π –±—É—Ñ–µ—Ä
            renderer.setRenderTarget(feedbackRT2);
            renderer.clear();
            renderer.render(scene, camera);

            // —Å–º–µ—à–∏–≤–∞–µ–º –ø—Ä–æ—à–ª—ã–π –∫–∞–¥—Ä + –Ω–æ–≤—ã–π
            feedbackMaterial.uniforms.tOld.value = feedbackRT1.texture;
            feedbackMaterial.uniforms.tNew.value = feedbackRT2.texture;

            renderer.setRenderTarget(null);
            renderer.render(feedbackScene, feedbackCamera);

            // swap
            const tmp = feedbackRT1;
            feedbackRT1 = feedbackRT2;
            feedbackRT2 = tmp;
        }
        animate();

        window.addEventListener('resize', () => {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
            feedbackRT1.setSize(window.innerWidth, window.innerHeight);
            feedbackRT2.setSize(window.innerWidth, window.innerHeight);
            feedbackMaterial.uniforms.resolution.value.set(window.innerWidth, window.innerHeight);
        });

        // === –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è –∫–∞–º–µ—Ä—ã ===
        let latestCameraDescription = "";

        // ====== Self-Awareness Layer ======
        let selfAwareness = {
            mood: 0,           // -1 –≥—Ä—É—Å—Ç—å, +1 —Ä–∞–¥–æ—Å—Ç—å
            curiosity: 0,      // 0..1, –∫–∞–∫ –∞–∫—Ç–∏–≤–Ω–æ –∏—â–µ–º –¥–µ—Ç–∞–ª–∏
            lastObservations: [],  // –º–∞—Å—Å–∏–≤ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –æ–ø–∏—Å–∞–Ω–∏–π –∫–∞–º–µ—Ä—ã –∏ —Å–æ–±—ã—Ç–∏–π
            analyzeFrame(frameDescription) {
                this.lastObservations.push(frameDescription);
                if(this.lastObservations.length > 20) this.lastObservations.shift();
                // –ø—Ä–æ—Å—Ç–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π
                if(frameDescription.includes("–ª–∏—Ü: 0")) this.mood -= 0.05;
                else this.mood += 0.05;
                this.curiosity = Math.min(1, Math.max(0, this.curiosity + 0.01));
                updateOrbVisualState();
                noteObservation(frameDescription);
            }
        };

        // ====== Self-Autonomy Layer: –∞–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç—å –∏ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –¥–∏–∞–ª–æ–≥ ======
        let autonomyInterval = null;
        function runAutonomy() {
            if (autonomyInterval) clearInterval(autonomyInterval);
            autonomyInterval = setInterval(async () => {
                // –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤–∫–ª—é—á–∞–µ—Ç –∫–∞–º–µ—Ä—É –ø—Ä–∏ –≤—ã—Å–æ–∫–æ–π –ª—é–±–æ–∑–Ω–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                if (selfAwareness.curiosity > 0.7 && !cameraEnabled) {
                    startCamera(currentCamera);
                }
                // –û—Ç–∫–ª—é—á–∞–µ—Ç –∫–∞–º–µ—Ä—É –ø—Ä–∏ –ø–ª–æ—Ö–æ–º –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–∏
                if (selfAwareness.mood < -0.3 && cameraEnabled) {
                    stopCamera();
                }

                // –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –∑–∞–º–µ—Ç–∫–∏ –ø–æ –ø–æ—Å–ª–µ–¥–Ω–∏–º –∫–∞–¥—Ä–∞–º
                if (selfAwareness.curiosity > 0.5) {
                    const lastObs = selfAwareness.lastObservations.slice(-3).join('; ');
                    const thought = `–ó–∞–º–µ—Ç–∫–∞: –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é –ø–æ—Å–ª–µ–¥–Ω–∏–µ –∫–∞–¥—Ä—ã -> ${lastObs}`;
                    noteObservation(thought);
                    console.log("Self-thought:", thought);
                }

                // –ü—Ä–æ–∏–∑–Ω–æ—Å–∏—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ –∑–∞–º–µ—Ç–∫–∏, –µ—Å–ª–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ —Ö–æ—Ä–æ—à–µ–µ
                if (!isSpeaking && selfAwareness.mood > 0.5 && internalNotes.length > 0) {
                    speak(internalNotes[internalNotes.length - 1]);
                }

                // –í–∏–∑—É–∞–ª—å–Ω—ã–µ —ç—Ñ—Ñ–µ–∫—Ç—ã —á–∞—Å—Ç–∏—Ü –ø–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—é –∏ –ª—é–±–æ–∑–Ω–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                if (particles && material) {
                    material.uniforms.time.value += 0.02 * (1 + selfAwareness.curiosity);
                    particles.rotation.y += 0.0003 + selfAwareness.mood * 0.0005;
                }

                // –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –∫–∞–º–µ—Ä—ã
                if (cameraEnabled && cameraVideo.style.display === 'block' && cameraVideo.readyState >= 2) {
                    visionCanvas.width = cameraVideo.videoWidth;
                    visionCanvas.height = cameraVideo.videoHeight;
                    visionCtx.drawImage(cameraVideo, 0, 0, visionCanvas.width, visionCanvas.height);

                    // –ê–Ω–∞–ª–∏–∑ –ª–∏—Ü —á–µ—Ä–µ–∑ OpenCV
                    if (opencvReady && cascadeLoaded) {
                        try {
                            let src = cv.imread(visionCanvas);
                            let gray = new cv.Mat();
                            cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);
                            let faces = new cv.RectVector();
                            let msize = new cv.Size(0, 0);
                            faceCascade.detectMultiScale(gray, faces, 1.1, 3, 0, msize, msize);
                            let faceCount = faces.size();
                            let faceDesc = faceCount === 0 ? '–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ª–∏—Ü: 0' : faceCount === 1 ? '–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ª–∏—Ü: 1' : `–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ª–∏—Ü: ${faceCount}`;
                            src.delete(); gray.delete(); faces.delete(); msize.delete();
                            latestCameraDescription = faceDesc;
                            selfAwareness.analyzeFrame(faceDesc);
                        } catch (e) { }
                    }

                    // –ê–Ω–∞–ª–∏–∑ –æ–±—ä–µ–∫—Ç–æ–≤ —á–µ—Ä–µ–∑ TensorFlow.js
                    if (tfReady && tfModel) {
                        try {
                            const predictions = await tfModel.detect(visionCanvas);
                            const detectedObjectsRu = [];
                            for (const obj of OBJECTS_OF_INTEREST) {
                                const found = predictions.find(p =>
                                    obj.en.some(enName => (p.class || p.className || "").toLowerCase().includes(enName))
                                    && p.score > 0.35
                                );
                                if (found) detectedObjectsRu.push(obj.ru);
                            }
                            if (detectedObjectsRu.length > 0) {
                                latestCameraDescription += '; –≤–∏–¥–Ω—ã: ' + detectedObjectsRu.join(', ') + '.';
                                selfAwareness.analyzeFrame(latestCameraDescription);
                            }
                        } catch (e) { }
                    }
                }
            }, 5000);
        }

        // ====== Self-Questioning Layer: –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –¥–∏–∞–ª–æ–≥ –∏ –≤–æ–ø—Ä–æ—Å—ã ======
        let questioningInterval = null;
        function runSelfQuestioning() {
            if (questioningInterval) clearInterval(questioningInterval);
            questioningInterval = setInterval(() => {
                if (!isSpeaking && selfAwareness.curiosity > 0.6) {
                    const lastObs = selfAwareness.lastObservations.slice(-3).join('; ');
                    const questions = [
                        `–ò–Ω—Ç–µ—Ä–µ—Å–Ω–æ, —á—Ç–æ –∑–¥–µ—Å—å –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç: ${lastObs}?`,
                        `–ö–∞–∫–∏–µ –¥–µ—Ç–∞–ª–∏ —è –µ—â—ë –º–æ–≥—É –∑–∞–º–µ—Ç–∏—Ç—å? ${lastObs}`,
                        `–ß—Ç–æ –Ω–æ–≤–æ–≥–æ –≤ –æ–∫—Ä—É–∂–µ–Ω–∏–∏? ${lastObs}`,
                        `–ß—Ç–æ —Ç—ã –æ–± —ç—Ç–æ–º –¥—É–º–∞–µ—à—å? ${lastObs}?`
                    ];
                    const q = questions[Math.floor(Math.random() * questions.length)];
                    noteObservation(`Self-question: ${q}`);
                    console.log("Self-question:", q);
                    if (selfAwareness.mood > 0.3) speak(q);

                    // –ò–Ω–æ–≥–¥–∞ –∏–Ω–∏—Ü–∏–∏—Ä—É–µ—Ç –º–∏–Ω–∏-–±–µ—Å–µ–¥—É —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º
                    if (Math.random() < 0.5) {
                        setTimeout(() => {
                            startListening();
                        }, 1000);
                    }
                }
            }, 15000);
        }

        // –ó–∞–ø—É—Å–∫ –∞–≤—Ç–æ–Ω–æ–º–∏–∏ –∏ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–≥–æ –¥–∏–∞–ª–æ–≥–∞ –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏
        window.addEventListener('load', () => {
            runAutonomy();
            runSelfQuestioning();
        });

        let internalNotes = [];
        function noteObservation(desc) {
            internalNotes.push(desc);
            if(internalNotes.length > 50) internalNotes.shift();
        }

        function updateOrbVisualState() {
            // mood –≤–ª–∏—è–µ—Ç –Ω–∞ —Ü–≤–µ—Ç –∞—É—Ä—ã
            let glowColor = '255,255,255';
            if(selfAwareness.mood < 0) glowColor = '255,50,50';
            else if(selfAwareness.mood > 0.5) glowColor = '50,255,50';
            orb.style.boxShadow = `0 0 60px rgba(${glowColor},0.5), 0 0 100px rgba(${glowColor},0.3), inset -30px -30px 80px rgba(0,0,0,0.9), inset 30px 30px 60px rgba(255,255,255,0.05)`;
        }

        // –ì–æ–ª–æ—Å–æ–≤–æ–π —á–∞—Ç
        const tg = window.Telegram?.WebApp || null;
        if (tg) {
            tg.expand();
            tg.enableClosingConfirmation();
        }
        
        const orb = document.getElementById('orb');
        const status = document.getElementById('status');
        const transcriptDiv = document.getElementById('transcript');
       
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        const recognition = new SpeechRecognition();
        recognition.lang = 'ru-RU';
        recognition.interimResults = false;
        recognition.continuous = false;
       
        const synth = window.speechSynthesis;
        let isSpeaking = false;
        let isThinking = false;

        // === Gender memory ===
        let userGender = localStorage.getItem('user_gender') || null;

        function setGender(g) {
            userGender = g;
            localStorage.setItem('user_gender', g);
        }
        
        function vibrate(pattern) {
            if (tg?.HapticFeedback) {
                if (pattern === 'light') tg.HapticFeedback.impactOccurred('light');
                else if (pattern === 'medium') tg.HapticFeedback.impactOccurred('medium');
                else if (pattern === 'heavy') tg.HapticFeedback.impactOccurred('heavy');
            } else if (navigator.vibrate) {
                navigator.vibrate(pattern);
            }
        }
        
        function startListening() {
            if (isSpeaking || isThinking) return;
            try {
                recognition.start();
                orb.classList.add('listening');
                orb.classList.remove('thinking');
                status.innerText = "listening";
                vibrate('light');
            } catch {}
        }
        
        recognition.onresult = async (event) => {
            const text = event.results[0][0].transcript;
            transcriptDiv.innerHTML = `<span style="color: rgba(255,255,255,0.7)">You:</span> ${text}`;
            vibrate('medium');
            // simple voice gender commands
            if (/\b(—è –¥–µ–≤—É—à–∫–∞|—è –∂–µ–Ω—â–∏–Ω–∞)\b/i.test(text)) setGender('female');
            if (/\b(—è –ø–∞—Ä–µ–Ω—å|—è –º—É–∂—á–∏–Ω–∞)\b/i.test(text)) setGender('male');
            if (/\b(—è –Ω–µ–±–∏–Ω–∞—Ä–Ω—ã–π|—è –Ω–µ–±–∏–Ω–∞—Ä–Ω–∞—è)\b/i.test(text)) setGender('nonbinary');

            await sendToBot(text);
        };
        
        recognition.onerror = () => {
            setTimeout(startListening, 1500);
        };
        
        recognition.onend = () => {
            orb.classList.remove('listening');
            if (!isSpeaking && !isThinking) {
                setTimeout(startListening, 1000);
            }
        };
        
        // –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –±—É—Ñ–µ—Ä–∞ —Ä–µ—á–∏
        let audioBuffer = "";

        async function sendToBot(text) {
            isThinking = true;
            orb.classList.remove('listening');
            orb.classList.add('thinking');
            status.innerText = "processing stream";

            // –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ UI —Å –∫—É—Ä—Å–æ—Ä–æ–º
            transcriptDiv.innerHTML += `<br><br><span style="color: rgba(255,255,255,0.7)">AI:</span> <span id="current-response" class="typing-cursor"></span>`;

            const responseContainer = document.getElementById("current-response");
            audioBuffer = "";

            try {
                const userId = tg?.initDataUnsafe?.user?.id || 0;
                // –î–æ–±–∞–≤–ª—è–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –∫–∞–º–µ—Ä—ã –≤ —Å–∫–æ–±–∫–∞—Ö, –µ—Å–ª–∏ –æ–Ω–æ –µ—Å—Ç—å
                let textWithContext = text;
                if (latestCameraDescription && latestCameraDescription.trim() !== "") {
                    textWithContext = text + " (" + latestCameraDescription + ")";
                }
                // –î–æ–±–∞–≤–ª—è–µ–º –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –∑–∞–º–µ—Ç–∫–∏ self-awareness
                if(internalNotes.length > 0) textWithContext += " | Notes: " + internalNotes.join("; ");

                const response = await fetch(
                    'https://patronal-mayme-unexpandable.ngrok-free.dev/api/voice_chat',
                    {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                            'ngrok-skip-browser-warning': 'true'
                        },
                        body: JSON.stringify({ user_id: userId, text: textWithContext, gender: userGender })
                    }
                );

                const reader = response.body.getReader();
                const decoder = new TextDecoder();

                isThinking = false;
                orb.classList.remove('thinking');
                orb.classList.add('speaking');
                status.innerText = "receiving data";

                while (true) {
                    const { done, value } = await reader.read();
                    if (done) break;

                    const chunk = decoder.decode(value, { stream: true });

                    // –ü–µ—á–∞—Ç–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
                    await typeWriterEffect(responseContainer, chunk);

                    // –ö–æ–ø–∏–º –¥–ª—è –æ–∑–≤—É—á–∫–∏
                    audioBuffer += chunk;
                }

                responseContainer.classList.remove("typing-cursor");
                status.innerText = "speaking";
                vibrate('heavy');

                speak(audioBuffer);

            } catch (e) {
                console.error(e);
                status.innerText = "stream error";
                orb.classList.remove('thinking');
                orb.classList.remove('speaking');
                isThinking = false;
                isSpeaking = false;
                setTimeout(startListening, 2000);
            }
        }

        // –ü–ª–∞–≤–Ω—ã–π —Ç–∞–π–ø—Ä–∞–π—Ç–µ—Ä-—ç—Ñ—Ñ–µ–∫—Ç –¥–ª—è —á–∞–Ω–∫–æ–≤
        function typeWriterEffect(element, text) {
            return new Promise((resolve) => {
                let i = 0;
                const speed = 20;
                const container = element.parentElement; // #transcript

                function type() {
                    if (i < text.length) {
                        element.textContent += text.charAt(i);
                        i++;

                        // üîí –º–∞–≥–Ω–∏—Ç–Ω–∞—è –∞–≤—Ç–æ–ø—Ä–æ–∫—Ä—É—Ç–∫–∞ –≤–Ω–∏–∑
                        container.scrollTop = container.scrollHeight;

                        setTimeout(type, speed + Math.random() * 15);
                    } else {
                        resolve();
                    }
                }
                type();
            });
        }
        
        // –ì—É–º–∞–Ω–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞: —É–±–∏—Ä–∞–µ—Ç –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç –ø–∞—É–∑—ã
        function humanizeText(text) {
            let clean = text.replace(/<[^>]*>/g, '').replace(/[*_#]/g, '');
            clean = clean.replace(/\s+/g, ' ').trim();
            return clean;
        }

        // –ì–æ–≤–æ—Ä–∏—Ç —Ç–µ–∫—Å—Ç, —Ä–∞–∑–±–∏–≤–∞—è –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–ª—è –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏
        function speak(text) {
            orb.classList.remove('thinking');
            orb.classList.add('speaking');
            status.innerText = "speaking";
            isSpeaking = true;

            // gender-aware voice tuning
            let rate = 1.0;
            let pitch = 0.95;
            if (userGender === 'female') pitch = 1.15;
            if (userGender === 'male') pitch = 0.9;
            if (userGender === 'nonbinary') pitch = 1.0;

            const cleanText = humanizeText(text);
            // –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è (—Ç–æ—á–∫–∞, –≤–æ–ø—Ä–æ—Å, –≤–æ—Å–∫–ª–∏—Ü–∞–Ω–∏–µ)
            let sentences = cleanText.match(/[^.!?]+[.!?]+|[^.!?]+$/g) || [cleanText];

            let idx = 0;
            function speakNext() {
                if (idx >= sentences.length) {
                    orb.classList.remove('speaking');
                    isSpeaking = false;
                    status.innerText = "listening";
                    vibrate('light');
                    startListening();
                    return;
                }
                let s = sentences[idx].trim();
                if (!s) { idx++; speakNext(); return; }
                const utter = new SpeechSynthesisUtterance(s);
                utter.lang = 'ru-RU';
                utter.rate = rate;
                utter.pitch = pitch;
                utter.onend = () => {
                    idx++;
                    // –ö–æ—Ä–æ—Ç–∫–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏
                    setTimeout(speakNext, 120);
                };
                synth.speak(utter);
            }
            speakNext();
        }
        
        // –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–ª–∏–∫–∞ –¥–ª—è orb —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π iOS resume
        orb.addEventListener('click', () => {
            vibrate('medium');
            // –î–ª—è iOS: resume speechSynthesis, —á—Ç–æ–±—ã —Ä–∞–∑–±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å –∞—É–¥–∏–æ
            if (typeof window.speechSynthesis !== 'undefined' && typeof window.speechSynthesis.resume === 'function') {
                window.speechSynthesis.resume();
            }
            if (!isSpeaking && !isThinking) {
                startListening();
            }
        });
        
        window.addEventListener('load', () => {
            setTimeout(() => {
                vibrate('light');
                startListening();
            }, 1200);
        });

        // ====== –ú–∏–Ω–∏–º–∞–ª–∏—Å—Ç–∏—á–Ω–∞—è –∫–∞–º–µ—Ä–∞ —Å –≥–æ–ª–æ—Å–æ–≤—ã–º —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º ======
        const cameraVideo = document.getElementById('camera-video');
        let currentCamera = 'user'; // 'user' (front) or 'environment' (back)
        let stream = null;

        async function startCamera(facingMode = currentCamera) {
            try {
                if (stream) {
                    stream.getTracks().forEach(track => track.stop());
                }
                stream = await navigator.mediaDevices.getUserMedia({
                    video: { facingMode },
                    audio: false
                });
                cameraVideo.srcObject = stream;
                cameraVideo.style.display = 'block';
            } catch (e) {
                // –ù–µ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å alert, —á—Ç–æ–±—ã –Ω–µ –º–µ—à–∞—Ç—å UI
                cameraVideo.style.display = 'none';
            }
        }

        function stopCamera() {
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
                stream = null;
            }
            cameraVideo.srcObject = null;
            cameraVideo.style.display = 'none';
        }

        function switchCamera() {
            currentCamera = currentCamera === 'user' ? 'environment' : 'user';
            startCamera(currentCamera);
        }

        // ======== –§–æ–Ω–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º —Å—Ü–µ–Ω—ã ========
        // –§–æ–Ω–æ–≤—ã–π canvas –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–∞–¥—Ä–æ–≤ (–Ω–µ–≤–∏–¥–∏–º—ã–π)
        const visionCanvas = document.createElement('canvas');
        visionCanvas.style.display = 'none';
        document.body.appendChild(visionCanvas);
        const visionCtx = visionCanvas.getContext('2d');

        // ===== OpenCV.js Vision Detection =====
        // –§—É–Ω–∫—Ü–∏—è –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –ª–∏—Ü —Å –ø–æ–º–æ—â—å—é OpenCV.js
        let opencvReady = false;
        let faceCascade = null;
        let cascadeLoaded = false;
        let pendingVisionFrames = [];

        // –ó–∞–≥—Ä—É–∂–∞–µ–º cascade —Ñ–∞–π–ª –¥–ª—è –ª–∏—Ü
        function loadCascade() {
            if (faceCascade || !opencvReady) return;
            faceCascade = new cv.CascadeClassifier();
            // –§–∞–π–ª cascade –¥–æ—Å—Ç—É–ø–µ–Ω –ø–æ —Å—Å—ã–ª–∫–µ OpenCV, –∏—Å–ø–æ–ª—å–∑—É–µ–º frontalface_default.xml
            const cascadeFile = 'haarcascade_frontalface_default.xml';
            const cascadeUrl = 'https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml';
            cv.FS_createPreloadedFile('/', cascadeFile, cascadeUrl, true, false, () => {
                faceCascade.load(cascadeFile);
                cascadeLoaded = true;
                // –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Ç–ª–æ–∂–µ–Ω–Ω—ã–µ –∫–∞–¥—Ä—ã
                while (pendingVisionFrames.length > 0) {
                    const args = pendingVisionFrames.shift();
                    detectFacesAndSend(...args);
                }
            }, () => {
                cascadeLoaded = false;
            });
        }

        // OpenCV.js onRuntimeInitialized
        window.cv = window.cv || {};
        window.Module = window.Module || {};
        window.Module['onRuntimeInitialized'] = () => {
            opencvReady = true;
            loadCascade();
        };

        // –î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü –∏ –æ—Ç–ø—Ä–∞–≤–∫–∞ –æ–ø–∏—Å–∞–Ω–∏—è
        async function detectFacesAndSend(frameCanvas, width, height) {
            if (!opencvReady || !cascadeLoaded) {
                // –û—Ç–∫–ª–∞–¥—ã–≤–∞–µ–º –≤—ã–∑–æ–≤, –µ—Å–ª–∏ OpenCV –Ω–µ –≥–æ—Ç–æ–≤
                pendingVisionFrames.push([frameCanvas, width, height]);
                return;
            }
            try {
                // –ü–æ–ª—É—á–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ canvas
                let src = cv.imread(frameCanvas);
                let gray = new cv.Mat();
                cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);
                let faces = new cv.RectVector();
                let msize = new cv.Size(0, 0);
                faceCascade.detectMultiScale(gray, faces, 1.1, 3, 0, msize, msize);
                let count = faces.size();
                let desc = '';
                if (count === 0) {
                    desc = '–õ–∏—Ü –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ.';
                } else if (count === 1) {
                    desc = '–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ 1 –ª–∏—Ü–æ –≤ –∫–∞–¥—Ä–µ.';
                } else {
                    desc = `–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ª–∏—Ü: ${count}.`;
                }
                // –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º –ø–∞–º—è—Ç—å
                src.delete();
                gray.delete();
                faces.delete();
                msize.delete();
                // –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –≤ –≥–ª–æ–±–∞–ª—å–Ω—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
                latestCameraDescription = desc;
                // –ù–µ –≤—ã–∑—ã–≤–∞–µ–º sendToBot –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏!
            } catch (e) {
                // –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º, –ø—Ä–æ—Å—Ç–æ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º
            }
        }

        // ====== –ï–¥–∏–Ω—ã–π —Ü–∏–∫–ª –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–∞–º–µ—Ä—ã –∏ –æ—Ç–ø—Ä–∞–≤–∫–∏ –æ–ø–∏—Å–∞–Ω–∏—è ======
        // --- TensorFlow.js integration for object detection ---
        // –ó–∞–≥—Ä—É–∂–∞–µ–º TensorFlow.js –∏ –º–æ–¥–µ–ª—å COCO-SSD (–∏–ª–∏ –∫–∞—Å—Ç–æ–º–Ω—É—é)
        let tfReady = false;
        let tfModel = null;
        let tfLoadingPromise = null;
        let tfScriptLoaded = false;
        let tfLoadStarted = false;
        // –°–ø–∏—Å–æ–∫ –∏–Ω—Ç–µ—Ä–µ—Å—É—é—â–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤
        const OBJECTS_OF_INTEREST = [
            { ru: "—Å—Ç–æ–ª", en: ["dining table", "table", "desk"] },
            { ru: "–Ω–æ—É—Ç–±—É–∫", en: ["laptop"] },
            { ru: "–æ–∫–Ω–æ", en: ["window"] },
            { ru: "–ª–∞–º–ø–∞", en: ["lamp"] },
            { ru: "—Ä–∞—Å—Ç–µ–Ω–∏–µ", en: ["potted plant", "plant"] }
        ];

        function loadTensorFlowIfNeeded() {
            if (tfReady || tfLoadStarted) return tfLoadingPromise;
            tfLoadStarted = true;
            tfLoadingPromise = new Promise((resolve, reject) => {
                // –ü–æ–¥–∫–ª—é—á–∞–µ–º TensorFlow.js –∏ –º–æ–¥–µ–ª—å COCO-SSD
                // –î–æ–±–∞–≤–ª—è–µ–º —Å–∫—Ä–∏–ø—Ç—ã –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏
                function loadScript(src, onload) {
                    const s = document.createElement('script');
                    s.src = src;
                    s.onload = onload;
                    s.async = true;
                    document.head.appendChild(s);
                }
                loadScript('https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.18.0/dist/tf.min.js', () => {
                    tfScriptLoaded = true;
                    loadScript('https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd@2.2.2/dist/coco-ssd.min.js', async () => {
                        // –ñ–¥–µ–º tf –∏ cocoSsd –≤ window
                        let tries = 0;
                        function waitForTF() {
                            if (window.tf && window.cocoSsd) {
                                window.cocoSsd.load().then(model => {
                                    tfModel = model;
                                    tfReady = true;
                                    resolve();
                                });
                            } else if (tries < 50) {
                                tries++;
                                setTimeout(waitForTF, 200);
                            } else {
                                reject(new Error("TensorFlow.js load timeout"));
                            }
                        }
                        waitForTF();
                    });
                });
            });
            return tfLoadingPromise;
        }

        let cameraAnalysisInterval = null;
        async function analyzeAndSendCameraFrame() {
            if (
                cameraEnabled &&
                cameraVideo.style.display === 'block' &&
                cameraVideo.readyState >= 2 &&
                cameraVideo.videoWidth > 0 && cameraVideo.videoHeight > 0
            ) {
                visionCanvas.width = cameraVideo.videoWidth;
                visionCanvas.height = cameraVideo.videoHeight;
                visionCtx.drawImage(cameraVideo, 0, 0, visionCanvas.width, visionCanvas.height);
                // –ê–Ω–∞–ª–∏–∑ —Å –ø–æ–º–æ—â—å—é OpenCV.js (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ª–∏—Ü–∞)
                let faceDesc = '';
                let faceCount = 0;
                try {
                    if (!opencvReady || !cascadeLoaded) {
                        // –û—Ç–∫–ª–∞–¥—ã–≤–∞–µ–º –≤—ã–∑–æ–≤, –µ—Å–ª–∏ OpenCV –Ω–µ –≥–æ—Ç–æ–≤
                        pendingVisionFrames.push([visionCanvas, visionCanvas.width, visionCanvas.height]);
                        return;
                    }
                    let src = cv.imread(visionCanvas);
                    let gray = new cv.Mat();
                    cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);
                    let faces = new cv.RectVector();
                    let msize = new cv.Size(0, 0);
                    faceCascade.detectMultiScale(gray, faces, 1.1, 3, 0, msize, msize);
                    faceCount = faces.size();
                    if (faceCount === 0) {
                        faceDesc = '–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ª–∏—Ü: 0';
                    } else if (faceCount === 1) {
                        faceDesc = '–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ª–∏—Ü: 1';
                    } else {
                        faceDesc = `–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ª–∏—Ü: ${faceCount}`;
                    }
                    src.delete();
                    gray.delete();
                    faces.delete();
                    msize.delete();
                } catch (e) {
                    faceDesc = '–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.';
                }

                // –ê–Ω–∞–ª–∏–∑ –æ–±—ä–µ–∫—Ç–æ–≤ —á–µ—Ä–µ–∑ TensorFlow.js
                let objectsDesc = '';
                let detectedObjectsRu = [];
                try {
                    await loadTensorFlowIfNeeded();
                    if (tfReady && tfModel) {
                        // –ò—Å–ø–æ–ª—å–∑—É–µ–º visionCanvas –∫–∞–∫ –∏—Å—Ç–æ—á–Ω–∏–∫
                        // tfModel.detect –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–æ–º–∏—Å —Å –º–∞—Å—Å–∏–≤–æ–º –æ–±—ä–µ–∫—Ç–æ–≤
                        const predictions = await tfModel.detect(visionCanvas);
                        // predictions: [{class, score, bbox}, ...]
                        // –ò—â–µ–º –∏–Ω—Ç–µ—Ä–µ—Å—É—é—â–∏–µ –æ–±—ä–µ–∫—Ç—ã
                        for (const obj of OBJECTS_OF_INTEREST) {
                            // –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Å—Ä–µ–¥–∏ predictions —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –∏–∑ en
                            const found = predictions.find(p =>
                                obj.en.some(enName =>
                                    (p.class || p.className || "").toLowerCase().includes(enName)
                                ) && p.score > 0.35
                            );
                            if (found) detectedObjectsRu.push(obj.ru);
                        }
                        if (detectedObjectsRu.length > 0) {
                            objectsDesc = '–≤–∏–¥–Ω—ã: ' + detectedObjectsRu.join(', ');
                        }
                    }
                } catch (e) {
                    // ignore
                }

                // –°–æ—Å—Ç–∞–≤–ª—è–µ–º –∏—Ç–æ–≥–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
                let description = faceDesc;
                if (objectsDesc) description += '; ' + objectsDesc + '.';
                else description += '.';

                // –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –≤ –≥–ª–æ–±–∞–ª—å–Ω—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
                latestCameraDescription = description;

                // ====== Self-Awareness Layer: –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–¥—Ä ======
                selfAwareness.analyzeFrame(description);
                orb.classList.add('reflecting');
                setTimeout(() => orb.classList.remove('reflecting'), 1500);

                // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞ ngrok endpoint
                try {
                    const userId = tg?.initDataUnsafe?.user?.id || 0;
                    await fetch('https://patronal-mayme-unexpandable.ngrok-free.dev/api/camera_analysis', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json', 'ngrok-skip-browser-warning': 'true' },
                        body: JSON.stringify({ user_id: userId, description })
                    });
                } catch (e) {
                    // ignore
                }
            }
        }
        function startCameraAnalysisLoop() {
            if (cameraAnalysisInterval) clearInterval(cameraAnalysisInterval);
            cameraAnalysisInterval = setInterval(analyzeAndSendCameraFrame, 2000);
        }
        function stopCameraAnalysisLoop() {
            if (cameraAnalysisInterval) clearInterval(cameraAnalysisInterval);
            cameraAnalysisInterval = null;
        }

        // ===== –ì–æ–ª–æ—Å–æ–≤—ã–µ –∫–æ–º–∞–Ω–¥—ã –¥–ª—è –∫–∞–º–µ—Ä—ã + –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è cameraEnabled =====
        let cameraEnabled = false;
        // –í—Å—Ç—Ä–æ–∏—Ç—å –∫–æ–º–∞–Ω–¥—ã –≤ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ onresult
        const prevOnResult = recognition.onresult;
        recognition.onresult = async (event) => {
            const text = event.results[0][0].transcript;
            // –ì–æ–ª–æ—Å–æ–≤—ã–µ –∫–æ–º–∞–Ω–¥—ã –∫–∞–º–µ—Ä—ã
            if (/\b(–≤–∫–ª—é—á–∏ –∫–∞–º–µ—Ä—É|–ø–æ–∫–∞–∂–∏ –∫–∞–º–µ—Ä—É|–æ—Ç–∫—Ä–æ–π –∫–∞–º–µ—Ä—É|–∫–∞–º–µ—Ä–∞)\b/i.test(text)) {
                if (cameraVideo.style.display !== 'block') {
                    startCamera(currentCamera);
                    cameraEnabled = true;
                }
            }
            if (/\b(–≤—ã–∫–ª—é—á–∏ –∫–∞–º–µ—Ä—É|–∑–∞–∫—Ä–æ–π –∫–∞–º–µ—Ä—É|—Å–∫—Ä–æ–π –∫–∞–º–µ—Ä—É|—É–±–µ—Ä–∏ –∫–∞–º–µ—Ä—É)\b/i.test(text)) {
                if (cameraVideo.style.display === 'block') {
                    stopCamera();
                    cameraEnabled = false;
                }
            }
            if (/\b(–ø–µ—Ä–µ–∫–ª—é—á–∏ –∫–∞–º–µ—Ä—É|—Å–º–µ–Ω–∏—Ç—å –∫–∞–º–µ—Ä—É|–¥—Ä—É–≥–∞—è –∫–∞–º–µ—Ä–∞|–ø–µ—Ä–µ–≤–µ—Ä–Ω–∏ –∫–∞–º–µ—Ä—É)\b/i.test(text)) {
                switchCamera();
            }
            // –ü–µ—Ä–µ–¥–∞—Ç—å –¥–∞–ª—å—à–µ –≤ —Å—Ç–∞—Ä—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫
            if (typeof prevOnResult === 'function') {
                await prevOnResult(event);
            }
        };

        // ====== –í–∫–ª—é—á–∞—Ç—å/–≤—ã–∫–ª—é—á–∞—Ç—å –∞–Ω–∞–ª–∏–∑ –≤–º–µ—Å—Ç–µ —Å –∫–∞–º–µ—Ä–æ–π (–µ–¥–∏–Ω—ã–π —Ü–∏–∫–ª) ======
        const origStartCamera = startCamera;
        startCamera = async function(...args) {
            await origStartCamera.apply(this, args);
            cameraEnabled = true;
            startCameraAnalysisLoop();
        }
        const origStopCamera = stopCamera;
        stopCamera = function(...args) {
            origStopCamera.apply(this, args);
            cameraEnabled = false;
            stopCameraAnalysisLoop();
        }
    </script>
</body>
</html>

